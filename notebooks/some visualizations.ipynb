{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "    \n",
    "def moving_average(l, n=10):\n",
    "    cumsum, moving_aves = [0], []\n",
    "    for i, x in enumerate(l, 1):\n",
    "        cumsum.append(cumsum[i-1] + x)\n",
    "        if i>=n:\n",
    "            moving_ave = (cumsum[i] - cumsum[i-n])/n\n",
    "            moving_aves.append(moving_ave)\n",
    "    return moving_aves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_train_train_loss, meta_train_valid_loss = [], []\n",
    "meta_train_train_acc, meta_train_valid_acc = [], []\n",
    "meta_valid_train_loss, meta_valid_valid_loss = [], []\n",
    "meta_valid_train_acc, meta_valid_valid_acc = [], []\n",
    "\n",
    "meta_train_loss_ratio = []\n",
    "meta_train_acc_ratio = []\n",
    "meta_valid_loss_ratio = []\n",
    "meta_valid_acc_ratio = []\n",
    "\n",
    "for meta in open('../log/meta_training_history.txt'): \n",
    "    meta = meta.split()\n",
    "    title = meta[0]\n",
    "    meta_results = meta[1].split(',')\n",
    "    if title == \"META_TRAIN_TRAIN:\":\n",
    "        meta_train_train_loss.append(float(meta_results[0]))\n",
    "        meta_train_train_acc.append(float(meta_results[1]))\n",
    "    elif title == \"META_TRAIN_VALID:\":\n",
    "        meta_train_valid_loss.append(float(meta_results[0]))\n",
    "        meta_train_valid_acc.append(float(meta_results[1]))\n",
    "    elif title == \"META_VALID_TRAIN:\": \n",
    "        meta_valid_train_loss.append(float(meta_results[0]))\n",
    "        meta_valid_train_acc.append(float(meta_results[1]))\n",
    "    elif title == \"META_VALID_VALID:\":\n",
    "        meta_valid_valid_loss.append(float(meta_results[0]))\n",
    "        meta_valid_valid_acc.append(float(meta_results[1]))\n",
    "    elif title == \"META_TRAIN_RATIO:\":\n",
    "        meta_train_loss_ratio.append(float(meta_results[0]))\n",
    "        meta_train_acc_ratio.append(float(meta_results[1]))\n",
    "    elif title == \"META_VALID_RATIO:\": \n",
    "        meta_valid_loss_ratio.append(float(meta_results[0]))\n",
    "        meta_valid_acc_ratio.append(float(meta_results[1]))\n",
    "        \n",
    "avg_n = 16\n",
    "\n",
    "meta_train_train_loss = moving_average(meta_train_train_loss, n=avg_n)\n",
    "meta_train_valid_loss = moving_average(meta_train_valid_loss, n=avg_n)\n",
    "meta_train_train_acc = moving_average(meta_train_train_acc, n=avg_n)\n",
    "meta_train_valid_acc = moving_average(meta_train_valid_acc, n=avg_n)\n",
    "meta_train_loss_ratio = moving_average(meta_train_loss_ratio, n=avg_n)\n",
    "meta_train_acc_ratio = moving_average(meta_train_acc_ratio, n=avg_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_conf_log = []\n",
    "i = 0\n",
    "for line in open('../log/train-meta-model.log'):\n",
    "    if line.startswith('2018'):\n",
    "        if i == 0 : i += 1\n",
    "        else: break\n",
    "    else:\n",
    "        training_conf_log.append(line)\n",
    "\n",
    "print('TRAINING CONFIGURATION:')\n",
    "print(''.join(training_conf_log))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
    "\n",
    "train, = plt.plot(meta_train_train_loss, '-o', label='train')\n",
    "valid, = plt.plot(meta_train_valid_loss, '-o', label='valid')\n",
    "plt.legend(handles=[train, valid])\n",
    "plt.title(\"Average meta-batch loss (meta-train, moving average n = {})\".format(avg_n))\n",
    "plt.show()\n",
    "\n",
    "train, = plt.plot(meta_train_train_acc, '-o', label='train')\n",
    "valid, = plt.plot(meta_train_valid_acc, '-o', label='valid')\n",
    "plt.legend(handles=[train, valid])\n",
    "plt.title(\"Average meta-batch accuracy (meta-train, moving average n = {})\".format(avg_n))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(meta_train_loss_ratio, '-o', label='train')\n",
    "plt.title(\"Average meta-batch ratio of valid loss to train loss (meta-train, moving average n = {})\".format(avg_n))\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(meta_train_acc_ratio, '-o', label='train')\n",
    "# plt.title(\"Average meta-batch ratio of valid accuracy to train accuracy (meta-train, moving average n = {})\".format(avg_n))\n",
    "# plt.show()\n",
    "\n",
    "train, = plt.plot(meta_valid_train_loss, '-o', label='train')\n",
    "valid, = plt.plot(meta_valid_valid_loss, '-o', label='valid')\n",
    "plt.legend(handles=[train, valid])\n",
    "plt.title(\"Average loss (meta-valid)\")\n",
    "plt.show()\n",
    "\n",
    "train, = plt.plot(meta_valid_train_acc, '-o', label='train')\n",
    "valid, = plt.plot(meta_valid_valid_acc, '-o', label='valid')\n",
    "plt.legend(handles=[train, valid])\n",
    "plt.title(\"Average accuracy (meta-valid)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(meta_valid_loss_ratio, '-o', label='train')\n",
    "plt.title(\"Average ratio of valid loss to train loss (meta-valid)\")\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(meta_valid_acc_ratio, '-o', label='train')\n",
    "# plt.title(\"Average ratio of valid accuracy to train accuracy (meta-valid)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for comparison of meta-optimizer with SGD and Adam\n",
    "\n",
    "import os\n",
    "from src.datasets.cifar import load_cifar100, cifar_input_shape\n",
    "from src.datasets.metadataset import load_meta_dataset\n",
    "\n",
    "from src.training.training_configuration import read_configuration\n",
    "from src.model.learner.simple_cnn import build_simple_cnn\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "train_conf_path = os.path.join(os.environ['CONF_DIR'], 'training_configuration.yml')\n",
    "conf = read_configuration(train_conf_path)\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_cifar100()\n",
    "\n",
    "meta_dataset_path = '../data/cifar100_64_64_2.h5'\n",
    "meta_dataset = load_meta_dataset(meta_dataset_path, X_train)\n",
    "\n",
    "learner = build_simple_cnn(cifar_input_shape, conf.classes_per_learner_set)\n",
    "\n",
    "learner_weights_path = os.path.join(os.environ['LOG_DIR'], \"learner_weights.h5\")\n",
    "learner.load_weights(learner_weights_path)\n",
    "initial_learner_weights = learner.get_weights()\n",
    "\n",
    "best_sgd_lr = 0.025\n",
    "best_adam_lr = 0.0007\n",
    "\n",
    "learner.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0))  # dummy optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best LR for SGD optimizer\n",
    "\n",
    "from src.utils.comparison import learning_rate_grid_search\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "trainings_per_dataset = 4\n",
    "\n",
    "def sgd_factory(lr):\n",
    "    return SGD(lr=lr)\n",
    "\n",
    "best_sgd_lr = learning_rate_grid_search(\n",
    "                 optimizer_factory=sgd_factory,\n",
    "                 meta_dataset=meta_dataset,\n",
    "                 lr_values=[0.02, 0.025, 0.03],\n",
    "                 n_learner_batches=conf.n_learner_batches,\n",
    "                 learner_batch_size=conf.learner_batch_size,\n",
    "                 learner=learner,\n",
    "                 trainings_per_dataset=trainings_per_dataset,\n",
    "                 initial_learner_weights=initial_learner_weights)\n",
    "\n",
    "print(\"Best SGD LR:\", best_sgd_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best LR for Adam optimizer\n",
    "\n",
    "from src.utils.comparison import learning_rate_grid_search\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "trainings_per_dataset = 4\n",
    "\n",
    "def adam_factory(lr):\n",
    "    return Adam(lr=lr)\n",
    "    \n",
    "best_adam_lr = learning_rate_grid_search(\n",
    "                 optimizer_factory=adam_factory,\n",
    "                 meta_dataset=meta_dataset,\n",
    "                 lr_values=[0.00065, 0.00070, 0.00075],\n",
    "                 n_learner_batches=conf.n_learner_batches,\n",
    "                 learner_batch_size=conf.learner_batch_size,\n",
    "                 learner=learner,\n",
    "                 trainings_per_dataset=trainings_per_dataset,\n",
    "                 initial_learner_weights=initial_learner_weights)\n",
    "\n",
    "print(\"Best Adam LR:\", best_adam_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.comparison import compare_optimizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from src.model.meta_learner.lstm_model import lstm_meta_learner\n",
    "\n",
    "meta_model = lstm_meta_learner(learner=learner, hidden_state_size=conf.hidden_state_size,\n",
    "                               backpropagation_depth=conf.backpropagation_depth,\n",
    "                               initial_learning_rate=conf.initial_lr,\n",
    "                               debug_mode=conf.debug_mode)\n",
    "\n",
    "meta_model.predict_model.compile(loss='mae',  # we don't use loss here anyway\n",
    "                                 optimizer=SGD(lr=0.0))  # dummy optimizer\n",
    "\n",
    "best_meta_learner_weights_path = os.path.join(os.environ['LOG_DIR'], \"meta_weights_best.h5\")\n",
    "meta_model.load_weights(best_meta_learner_weights_path)\n",
    "\n",
    "meta_optimizer = meta_model.predict_model\n",
    "\n",
    "optimizers = [meta_optimizer, SGD(lr=best_sgd_lr), Adam(lr=best_adam_lr)]\n",
    "\n",
    "trainings_per_dataset = 4\n",
    "\n",
    "comparison_results = compare_optimizers(meta_dataset=meta_dataset,\n",
    "                                        optimizers=optimizers,\n",
    "                                        n_learner_batches=conf.n_learner_batches,\n",
    "                                        learner_batch_size=conf.learner_batch_size,\n",
    "                                        learner=learner,\n",
    "                                        trainings_per_dataset=trainings_per_dataset,\n",
    "                                        initial_learner_weights=initial_learner_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "comparison_results = [np.array(r) for r in comparison_results]\n",
    "\n",
    "for results, name in zip(comparison_results, ['meta', 'sgd', 'adam']):\n",
    "    print(\"\\n\" + \"*\" * 50)\n",
    "    print(name + \" optimizer:\")\n",
    "    print(\"average loss:\", results.mean())\n",
    "    print(\"loss std:\", results.std())\n",
    "    print(\"min loss:\", results.min())\n",
    "    print(\"max loss:\", results.max())\n",
    "    \n",
    "print(\"*\" * 50)\n",
    "\n",
    "sgd_vs_adam = [sgd - adam for sgd, adam in zip(comparison_results[1], comparison_results[2])]\n",
    "meta_vs_sgd = [meta - sgd for meta, sgd in zip(comparison_results[0], comparison_results[1])]\n",
    "meta_vs_adam = [meta - adam for meta, adam in zip(comparison_results[0], comparison_results[2])]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
    "\n",
    "plt.hist(sgd_vs_adam, bins=100)\n",
    "plt.title(\"SGD vs ADAM (loss with sgd - loss with adam)\")\n",
    "plt.show()\n",
    "\n",
    "worse_count = sum(1 if s > 0 else 0 for s in sgd_vs_adam)\n",
    "worse_percent = worse_count / len(sgd_vs_adam) * 100\n",
    "print(\"SGD was worse than ADAM in {}% trainings\".format(worse_percent))\n",
    "print(\"SGD was worst compared to ADAM when its loss was greater by {}\".format(max(sgd_vs_adam)))\n",
    "print(\"SGD was best compared to ADAM when its loss was less by {}\".format(min(sgd_vs_adam)))\n",
    "\n",
    "plt.hist(meta_vs_sgd, bins=100)\n",
    "plt.title(\"META vs SGD (loss with meta - loss with sgd)\")\n",
    "plt.show()\n",
    "\n",
    "worse_count = sum(1 if s > 0 else 0 for s in meta_vs_sgd)\n",
    "worse_percent = worse_count / len(meta_vs_sgd) * 100\n",
    "print(\"META was worse than SGD in {}% trainings\".format(worse_percent))\n",
    "print(\"META was worst compared to SGD when its loss was greater by {}\".format(max(meta_vs_sgd)))\n",
    "print(\"META was best compared to SGD when its loss was less by {}\".format(min(meta_vs_sgd)))\n",
    "\n",
    "plt.hist(meta_vs_adam, bins=100)\n",
    "plt.title(\"META vs ADAM (loss with meta - loss with adam)\")\n",
    "plt.show()\n",
    "\n",
    "worse_count = sum(1 if s > 0 else 0 for s in meta_vs_adam)\n",
    "worse_percent = worse_count / len(meta_vs_adam) * 100\n",
    "print(\"META was worse than ADAM in {}% trainings\".format(worse_percent))\n",
    "print(\"META was worst compared to ADAM when its loss was greater by {}\".format(max(meta_vs_adam)))\n",
    "print(\"META was best compared to ADAM when its loss was less by {}\".format(min(meta_vs_adam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
